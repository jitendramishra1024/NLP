{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA OBTAINED FROM \n",
    "#https://catalog.data.gov/dataset/consumer-complaint-database\n",
    "#INSPIRED FROM \n",
    "#https://towardsdatascience.com/multi-class-text-classification-with-scikit-learn-12f1e60e0a9f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROBLEM FORMULATION\n",
    "#The problem is supervised text classification problem, and our goal is to investigate which supervised machine learning \n",
    "#methods are best suited to solve it.\n",
    "#Given a new complaint comes in, we want to assign it to one of 12 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date received</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sub-product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Sub-issue</th>\n",
       "      <th>Consumer Complaint</th>\n",
       "      <th>Company Public Response</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>ZIP code</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Consumer consent provided?</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Date Sent to Company</th>\n",
       "      <th>Company Response to Consumer</th>\n",
       "      <th>Timely response?</th>\n",
       "      <th>Consumer disputed?</th>\n",
       "      <th>Complaint ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3/12/14</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Other mortgage</td>\n",
       "      <td>Loan modification,collection,foreclosure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M&amp;T BANK CORPORATION</td>\n",
       "      <td>MI</td>\n",
       "      <td>48382</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Referral</td>\n",
       "      <td>3/17/14</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>759217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10/1/16</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Incorrect information on credit report</td>\n",
       "      <td>Account status</td>\n",
       "      <td>I have outdated information on my credit repor...</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>TRANSUNION INTERMEDIATE HOLDINGS, INC.</td>\n",
       "      <td>AL</td>\n",
       "      <td>352XX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>10/5/16</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2141773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10/17/16</td>\n",
       "      <td>Consumer Loan</td>\n",
       "      <td>Vehicle loan</td>\n",
       "      <td>Managing the loan or lease</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I purchased a new car on XXXX XXXX. The car de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CITIZENS FINANCIAL GROUP, INC.</td>\n",
       "      <td>PA</td>\n",
       "      <td>177XX</td>\n",
       "      <td>Older American</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>10/20/16</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2163100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6/8/14</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bankruptcy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AMERICAN EXPRESS COMPANY</td>\n",
       "      <td>ID</td>\n",
       "      <td>83854</td>\n",
       "      <td>Older American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web</td>\n",
       "      <td>6/10/14</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>885638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9/13/14</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>Communication tactics</td>\n",
       "      <td>Frequent or repeated calls</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CITIBANK, N.A.</td>\n",
       "      <td>VA</td>\n",
       "      <td>23233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web</td>\n",
       "      <td>9/13/14</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1027760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date received           Product     Sub-product  \\\n",
       "0       3/12/14          Mortgage  Other mortgage   \n",
       "1       10/1/16  Credit reporting             NaN   \n",
       "2      10/17/16     Consumer Loan    Vehicle loan   \n",
       "3        6/8/14       Credit card             NaN   \n",
       "4       9/13/14   Debt collection     Credit card   \n",
       "\n",
       "                                      Issue                   Sub-issue  \\\n",
       "0  Loan modification,collection,foreclosure                         NaN   \n",
       "1    Incorrect information on credit report              Account status   \n",
       "2                Managing the loan or lease                         NaN   \n",
       "3                                Bankruptcy                         NaN   \n",
       "4                     Communication tactics  Frequent or repeated calls   \n",
       "\n",
       "                                  Consumer Complaint  \\\n",
       "0                                                NaN   \n",
       "1  I have outdated information on my credit repor...   \n",
       "2  I purchased a new car on XXXX XXXX. The car de...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                             Company Public Response  \\\n",
       "0                                                NaN   \n",
       "1  Company has responded to the consumer and the ...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                  Company State ZIP code            Tags  \\\n",
       "0                    M&T BANK CORPORATION    MI    48382             NaN   \n",
       "1  TRANSUNION INTERMEDIATE HOLDINGS, INC.    AL    352XX             NaN   \n",
       "2          CITIZENS FINANCIAL GROUP, INC.    PA    177XX  Older American   \n",
       "3                AMERICAN EXPRESS COMPANY    ID    83854  Older American   \n",
       "4                          CITIBANK, N.A.    VA    23233             NaN   \n",
       "\n",
       "  Consumer consent provided? Submitted via Date Sent to Company  \\\n",
       "0                        NaN      Referral              3/17/14   \n",
       "1           Consent provided           Web              10/5/16   \n",
       "2           Consent provided           Web             10/20/16   \n",
       "3                        NaN           Web              6/10/14   \n",
       "4                        NaN           Web              9/13/14   \n",
       "\n",
       "  Company Response to Consumer Timely response? Consumer disputed?  \\\n",
       "0      Closed with explanation              Yes                 No   \n",
       "1      Closed with explanation              Yes                 No   \n",
       "2      Closed with explanation              Yes                 No   \n",
       "3      Closed with explanation              Yes                Yes   \n",
       "4      Closed with explanation              Yes                Yes   \n",
       "\n",
       "   Complaint ID  \n",
       "0        759217  \n",
       "1       2141773  \n",
       "2       2163100  \n",
       "3        885638  \n",
       "4       1027760  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PART 01 :\n",
    "#DATA EXPLORATION \n",
    "import pandas as pd\n",
    "df = pd.read_csv('Consumer_Complaints.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9999, 18)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check shape \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART 02 \n",
    "#INPUT OUTPUT SEGREGATION \n",
    "#For this project, we need only two columns — “Product” and “Consumer complaint narrative”.\n",
    "#Input: Consumer_complaint_narrative\n",
    "#Output:Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART 03 \n",
    "#DATA CLEANING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all column except input and output \n",
    "col = ['Product', 'Consumer Complaint']\n",
    "df= df[col]\n",
    "#remove null review comments \n",
    "df= df[pd.notnull(df['Consumer Complaint'])]\n",
    "#rename the column from Consumer Complaint to Consumer_complaint\n",
    "df.columns=['Product', 'Consumer_complaint']\n",
    "#factorize the product and rename with categoryid \n",
    "df['category_id'] = df['Product'].factorize()[0]\n",
    "#remove duplicates \n",
    "df=df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Consumer_complaint</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>I have outdated information on my credit repor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Consumer Loan</td>\n",
       "      <td>I purchased a new car on XXXX XXXX. The car de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>An account on my credit report has a mistaken ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>This company refuses to provide me verificatio...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>This complaint is in regards to Square Two Fin...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Product                                 Consumer_complaint  \\\n",
       "1   Credit reporting  I have outdated information on my credit repor...   \n",
       "2      Consumer Loan  I purchased a new car on XXXX XXXX. The car de...   \n",
       "7   Credit reporting  An account on my credit report has a mistaken ...   \n",
       "12   Debt collection  This company refuses to provide me verificatio...   \n",
       "16   Debt collection  This complaint is in regards to Square Two Fin...   \n",
       "\n",
       "    category_id  \n",
       "1             0  \n",
       "2             1  \n",
       "7             0  \n",
       "12            2  \n",
       "16            2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2110, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preserve mapping of product to category id mapping \n",
    "category_id_df = df[['Product', 'category_id']].drop_duplicates().sort_values('category_id')\n",
    "category_to_id = dict(category_id_df.values)\n",
    "id_to_category = dict(category_id_df[['category_id', 'Product']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "df.groupby('Product').Consumer_complaint.count().plot.bar(ylim=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     518\n",
       "3     407\n",
       "0     392\n",
       "4     270\n",
       "6     185\n",
       "7     145\n",
       "1     108\n",
       "9      26\n",
       "8      22\n",
       "10     18\n",
       "12      9\n",
       "5       4\n",
       "13      2\n",
       "11      2\n",
       "15      1\n",
       "14      1\n",
       "Name: category_id, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see number of different category id available \n",
    "df['category_id'].value_counts()\n",
    "#we have 16 categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove product id \n",
    "# df =df.drop(df.loc[:,['Product']], axis =1 )\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now our df is ready #now we will go for Text Processig \n",
    "#PART -04 \n",
    "#TEXT PROCESSING \n",
    "# One common approach for extracting features from text is to use the bag of words model:\n",
    "#     a model where for each document, a complaint narrative in our case, the presence (and often the frequency) of words\n",
    "#     is taken into consideration, but the order in which they occur is ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(sublinear_tf= True, #use a logarithmic form for frequency\n",
    "                       min_df = 5, #minimum numbers of documents a word must be present in to be kept\n",
    "                       norm= 'l2', #ensure all our feature vectors have a euclidian norm of 1\n",
    "                       ngram_range= (1,2), #to indicate that we want to consider both unigrams and bigrams.\n",
    "                       stop_words ='english') #to remove all common pronouns to reduce the number of noisy features\n",
    "features = tfidf.fit_transform(df.Consumer_complaint).toarray()\n",
    "labels = df.category_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Details of TFIDF vectorization \n",
    "# We will use sklearn.feature_extraction.text.TfidfVectorizer to calculate a tf-idf vector for each of consumer complaint narratives:\n",
    "# ->sublinear_df is set to True to use a logarithmic form for frequency.\n",
    "# ->min_df is the minimum numbers of documents a word must be present in to be kept.\n",
    "# ->norm is set to l2, to ensure all our feature vectors have a euclidian norm of 1.\n",
    "# ->ngram_range is set to (1, 2) to indicate that we want to consider both unigrams and bigrams.\n",
    "# ->stop_words is set to \"english\" to remove all common pronouns (\"a\", \"the\", ...) to reduce the number of noisy features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2110, 3)\n",
      "(2110, 6069)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we know that in tfidf our data will be projected to 6069 columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7386    3\n",
       "780     4\n",
       "6882    0\n",
       "886     4\n",
       "8037    2\n",
       "       ..\n",
       "9468    6\n",
       "3856    2\n",
       "676     2\n",
       "4319    2\n",
       "8084    4\n",
       "Name: category_id, Length: 422, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multiclass classifier \n",
    "#lets start with  linear SVM \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Consumer_complaint'], df['category_id'], random_state= 0,test_size=0.2)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC().fit(X_train_tfidf, y_train)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict(tfidf.transform(['I have outdated information on my credit repor'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.79      0.73        68\n",
      "           1       0.78      0.41      0.54        17\n",
      "           2       0.73      0.85      0.79        98\n",
      "           3       0.86      0.92      0.89        91\n",
      "           4       0.78      0.72      0.75        58\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.72      0.76      0.74        41\n",
      "           7       1.00      0.80      0.89        30\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       1.00      0.29      0.44         7\n",
      "          10       0.00      0.00      0.00         3\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.77       422\n",
      "   macro avg       0.50      0.43      0.44       422\n",
      "weighted avg       0.76      0.77      0.76       422\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INE12363221\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_pred = clf.predict(tfidf.transform(X_test))\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7748815165876777"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so we are getting accuracy of 77% in case of linear SVM \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL SELECTION \n",
    "# We will benchmark the following four models:\n",
    "# Logistic Regression\n",
    "# (Multinomial) Naive Bayes\n",
    "# Linear Support Vector Machine\n",
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INE12363221\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\INE12363221\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\INE12363221\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\INE12363221\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "  model_name = model.__class__.__name__\n",
    "  accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n",
    "  for fold_idx, accuracy in enumerate(accuracies):\n",
    "    entries.append((model_name, fold_idx, accuracy))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>fold_idx</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>1</td>\n",
       "      <td>0.473934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>2</td>\n",
       "      <td>0.445498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>3</td>\n",
       "      <td>0.490521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>4</td>\n",
       "      <td>0.431280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>1</td>\n",
       "      <td>0.810427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>2</td>\n",
       "      <td>0.796209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>3</td>\n",
       "      <td>0.810427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>4</td>\n",
       "      <td>0.774882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0</td>\n",
       "      <td>0.684834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>1</td>\n",
       "      <td>0.691943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>2</td>\n",
       "      <td>0.663507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>3</td>\n",
       "      <td>0.682464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>4</td>\n",
       "      <td>0.658768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0</td>\n",
       "      <td>0.796209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>1</td>\n",
       "      <td>0.772512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>2</td>\n",
       "      <td>0.765403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>3</td>\n",
       "      <td>0.772512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>4</td>\n",
       "      <td>0.741706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model_name  fold_idx  accuracy\n",
       "0   RandomForestClassifier         0  0.469194\n",
       "1   RandomForestClassifier         1  0.473934\n",
       "2   RandomForestClassifier         2  0.445498\n",
       "3   RandomForestClassifier         3  0.490521\n",
       "4   RandomForestClassifier         4  0.431280\n",
       "5                LinearSVC         0  0.812796\n",
       "6                LinearSVC         1  0.810427\n",
       "7                LinearSVC         2  0.796209\n",
       "8                LinearSVC         3  0.810427\n",
       "9                LinearSVC         4  0.774882\n",
       "10           MultinomialNB         0  0.684834\n",
       "11           MultinomialNB         1  0.691943\n",
       "12           MultinomialNB         2  0.663507\n",
       "13           MultinomialNB         3  0.682464\n",
       "14           MultinomialNB         4  0.658768\n",
       "15      LogisticRegression         0  0.796209\n",
       "16      LogisticRegression         1  0.772512\n",
       "17      LogisticRegression         2  0.765403\n",
       "18      LogisticRegression         3  0.772512\n",
       "19      LogisticRegression         4  0.741706"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_name\n",
       "LinearSVC                 0.800948\n",
       "LogisticRegression        0.769668\n",
       "MultinomialNB             0.676303\n",
       "RandomForestClassifier    0.462085\n",
       "Name: accuracy, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df.groupby('model_name').accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOW LETS DO SAMETHING USING NTLTK \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Consumer_complaint</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I have outdated information on my credit repor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>I purchased a new car on XXXX XXXX. The car de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>An account on my credit report has a mistaken ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>This company refuses to provide me verificatio...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>This complaint is in regards to Square Two Fin...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Consumer_complaint  category_id\n",
       "1   I have outdated information on my credit repor...            0\n",
       "2   I purchased a new car on XXXX XXXX. The car de...            1\n",
       "7   An account on my credit report has a mistaken ...            0\n",
       "12  This company refuses to provide me verificatio...            2\n",
       "16  This complaint is in regards to Square Two Fin...            2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Consumer_Complaints.csv')\n",
    "#remove all column except input and output \n",
    "col = ['Product', 'Consumer Complaint']\n",
    "df= df[col]\n",
    "#remove null review comments \n",
    "df= df[pd.notnull(df['Consumer Complaint'])]\n",
    "#rename the column from Consumer Complaint to Consumer_complaint\n",
    "df.columns=['Product', 'Consumer_complaint']\n",
    "#factorize the product and rename with categoryid \n",
    "df['category_id'] = df['Product'].factorize()[0]\n",
    "#remove duplicates \n",
    "#remove product id \n",
    "df =df.drop(df.loc[:,['Product']], axis =1 )\n",
    "df=df.drop_duplicates()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outdat inform credit report previous disput yet remov inform seven year old not meet credit report requir',\n",
       " 'purchas new car xxxx xxxx car dealer call citizen bank get day payoff loan good till xxxx xxxx dealer sent check next day balanc checkbook xxxx xxxx notic citizen bank taken automat payment check account xxxx xxxx xxxx bank call citizen state not close loan xxxx xxxx state not receiv check xxxx xxxx told not believ check took long arriv xxxx told check issu amount overpaid deduct addit interest today xxxx xxxx call citizen bank talk supervisor name xxxx xxxx xxxx receiv letter loan paid full date xxxx xxxx refund check includ xxxx state hold payment busi day loan satisfi check would mail wed xx xx xxxx question delay post dealer payment first state sometim take busi day post said not receiv check till xxxx xxxx told not believ ask money state hold payment busi day ask simpli said polici ask would receiv interest money state believ citizen bank deliber delay post payment return consum money make addit interest bank not illeg hurt consum not ethic amount money lost minim thousand car loan month addit interest earn could stagger still anoth car loan citizen bank afraid trade car anoth year run problem',\n",
       " 'account credit report mistaken date mail debt valid letter allow xxxx correct inform receiv letter mail state experian receiv correspond found suspici n write experian letter word impli incap write letter deepli offend implic call experian figur letter suspici spoke repres incred unhelp not effect answer question ask kept ignor say regard offens letter disput process feel repres want not satisfi still not clear receiv letter type letter sign letter paid mail letter yet experian will disregard law request disgust entir situat would like disput handl appropri would like experian repres contact give real explan letter',\n",
       " 'compani refus provid verif valid debt per right fdcpa not believ debt mine',\n",
       " 'complaint regard squar two financi refer cfpb case number xxxx regard cach l l c squar two financi util entir social secur number includ date birth pfd document list complaint initi complaint cach l l c not squar two financi breach follow ident theft assumpt deterr act xxxx privaci act xxxx xxxx social secur xxxx xxxx privaci act carri maximum xxxx fine calendar cap year breach titl xxxx xxxx xxxx xxxx xxxx xxxx xxxx solut cach l l c handl correct not squar two financi two squar financi submit xxxx xxxx xxxx subscrib name form list cfpb case xxxx render liabl matter addit account number associ univers data form could use account number instead ssn dob xxxx xxxx xxxx also includ remov xxxx xxxx form cfpb case xxxx list pdf document attach case number squar two financi contact xxxxxxxxxxxx xxxx xxxx xxxx e mail regard matter addit inform not sale distribut via fax fax scan copi store retriev system record transmit digit electron without express written consent inform protect copyright publish law xxxx xxxx xxxx xxxx inform protect xxxx xxxx xxxx xxxx xxxx freedom speech xxxx xxxx xxxx includ uniform commerci code xxxx xxxx right reserv world wide',\n",
       " 'start refin home mortgag process cash option xx xx necessari document submit xxxx initi review got good faith estim loan amount close cost base estim deposit made toward apprais apprais came lesser amount agre reduc loan amount extent howev got revis estim less addit close cost toward point etc got numer revis estim differ loan amount close cost took month reach definit close document henc want get back deposit',\n",
       " 'xxxx ex husband appli refin heloc benefici loan grant ex husband pass away xxxx xxxx time contact lawyer determin option husband remov titl properti mortgag lawyer took care husband remov titl recent attempt appli refin remov mortgag take cash learn attempt refin unabl refin properti due deed xxxx found indic interest properti deed file xxxx counti illinoi record xxxx origin purchas home ex husband one list deed benefici file mortgag xxxx xxxx properti outrag point took loan home yet never deed name one right owner deni abil refin time not show right owner properti prior xxxx xxxx xxxx children quit claim father interest sick compani way compani mislead xxxx custom technic forc remain compani not secur financ anoth reput compani wait anywher month refin properti own year pay year consid inherit sinc quit claim xxxx xxxx xxxx',\n",
       " 'disput sever account credit report equifax sever time first disput origin creditor xxxx xxxx xxxx xxxx xxxx solut letter not receiv correspond proof sent copi letter certifi mail receipt credit bureau continu verifi debt without copi proof signatur statement disput also never put credit report equifax continu updat account associ creditor',\n",
       " 'mortgag transfer nationstar xxxx xxxx xxxx sinc payment not post time manner amount sent exampl payment clear bank xxxx xxxx xxxx xxxx per payment histori receiv nationstar payment not post xxxx xxxx xxxx amount xxxx payment clear bank xxxx xxxx xxxx xxxx not post account xxxx xxxx xxxx amount xxxx loan transfer nationstar xxxx receiv good letter xxxx welcom packag nationstar contact make sure payment amount xxxx told send post xxxx call everi month get payment histori not allow use websit tri get inform sever time take long post money less sent sent exact document attach state record send histori everi month post money sent unabl resolv issu nationstar not will listen review document sent proof sent call everi month sinc xxxx xxxx get payment histori deni send month',\n",
       " 'happi xxxx card member year late xx xx xxxx convert card portfolio barclaycard xxxx almost never carri balanc start xx xx xxxx barclay overcharg interest expens everi month instead charg interest carri balanc charg entir averag balanc charg last month carri previou month charg us interest charg doubl dip get interchang fee purchas equal apr plu get interest purchas equival interest charg feel practic uneth not illeg convert not choic xxxx barclaycard mastercard leav lose point acquir previou year complet unfair big financi hate reput hope folk investig',\n",
       " 'without provoc receiv notic credit line decreas nearli avail credit reduc xxxx xxxx rough amount avail balanc call question chang provid nob descript respons referenc xxxx report understand fcra entitl copi report refus citi given explan predatori affect util credit subject increas apr etc higher cost credit without reason',\n",
       " 'write request assist look decept practic collect law firm appear use tactic may violat consum protect law debt collect practic depriv consum right disput xxxx xxxx receiv notic compani next day contact offic instruct memo date xxxx xxxx xxxx instruct contact plaintiff attorney not court follow instruct provid contact plaintiff attorney phone also fax letter xxxx xxxx xxxx disput debt see letter compani respond letter date xxxx xxxx xxxx send bill due date xxxx request bill show balanc back made payment back xxxx xxxx disput amount owe disput charg wrote back compani fax anoth disput letter xxxx xxxx xxxx continu disput amount owe compani sent respons xxxx xxxx xxxx say furnish inform not disput owe xxxx xxxx disput balanc inaccur need proof last known charg activ account xxxx xxxx last paragraph letter indic disput amount send letter xxxx xxxx xxxx sent anoth letter compani disput balanc request document compani never respond xxxx xxxx letter sinc not commun xxxx xxxx xxxx receiv letter copi default judgment file court clerk offic indic fail respond judgment fact judgment firm serv origin judgment attach disput letter show respond instruct offic xxxx differ occas plaintiff fail respond disput furnish inform provid probabl unabl obtain proof origin debt instead use credibl legal procedur settl debt util unfaith dirti tactic violat right went court commit perjuri law file fals document court default judgment fail respond fact respond fail furnish proof went court hous clerk offic told compani not notifi offic contact instead compani told court clerk offic not respond summon clerk offic grant default judgement base fals inform not respond summon file fals affirm clerk offic',\n",
       " 'disput inaccur inform chex system credit report initi submit polic report xxxx xxxx chex system delet item mention letter not item actual list polic report word want say word word item fraudul total disregard polic report account state fraudul paid littl closer attent polic report would not posit would n research would like report inform remov xxxx xxxx xxxx',\n",
       " 'check credit report file complaint cfpb xxxx final abl get access disput form xxxx xxxx account schedul delet xx xx xxxx still record alreadi regist report number name social secur place disput disput cart attempt upload instruct taken anoth form request inform alreadi matter record order get access report first place screenshot attach design discourag',\n",
       " 'need move xxxx facil longer afford pay morthag would like moni paid mark paid full',\n",
       " 'attempt open xxxx xxxx account xxxx xxxx unabl due misinform credit report advis resolv issu disput inform not mine also would like say victim consum fraud want issu protect other abl access inform person gain posit not even open account fradul act need reciev proper treatment',\n",
       " 'experian allow xxxx pull hard credit inquiri without permiss done xxxx store xxxx xxxx xxxx sc store employe xxxx credit pull tri get revers want credit pull remov credit report immedi',\n",
       " 'fha loan us bank paid xxxx xxxx pay loan xxxx xxxx instead xxxx xxxx charg interest fee spoke us bank regard inform unwil refund charg even though interest charg exact day loan paid feel charg pay mortgag loan day month better word scam',\n",
       " 'toll would credit score xxxx end six month custom support specialist work case longer work fact lower score noth chang keep disput thing pay like car payment credit card etc compani parkview credit',\n",
       " 'went divorc sever year ago request home loan modif bank america bank america refus get back sever occas caus process take year destroy credit process got foreclosur judgment sent sheriff sale process correctli paid time year decid sell home list sale day receiv offer accept promptli got apart paid deposit sign leas move new apart day close prepar close discov purchas lender unknown bank america sold overdu princip hud requir us sell home break even hous apprais around mani foreclosur area contact bank america determin could inform buyer could process short sale immedi said would probabl not abl hope buyer still around went process continu request updat inform month process drag lost buyer could make mortgag payment rent payment apart continu work home modif process contact lawyer sever time receiv respons occass final xxxx xxxx receiv email back xxxx xxxx xxxx xxxx bank america attorney say loan servic releas xxxx xxxx immedi call restart process sent packet process submit packet gather info need wife drove hous sherrif sale notif xx xx xxxx bank america would longer work would never respond sold xxxx process sheriff sale began sheriff sale process inform lawyer longer servic loan call xxxx confirm bank america complet lastli log sheriff websit discov bank america bought see intent somehow gain process']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(df):\n",
    "    all_reviews = list()\n",
    "    lines = df[\"Consumer_complaint\"].values.tolist()\n",
    "    for text in lines:\n",
    "        text = text.lower()\n",
    "        text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "        words=nltk.word_tokenize(text)\n",
    "        stop_words= set(stopwords.words('english'))\n",
    "        stop_words.discard(\"not\")\n",
    "        words_without_stop_words=[word for word in words if word not in stop_words]\n",
    "        #words=[lemmatizer.lemmatize(word) for word in words_without_stop_words ]\n",
    "        words=[ps.stem(word) for word in words_without_stop_words ]\n",
    "        words = ' '.join(words)\n",
    "        all_reviews.append(words)\n",
    "    return all_reviews\n",
    "\n",
    "all_complaint = clean_text(df)\n",
    "all_complaint[0:20]  \n",
    "#print(len(all_complaint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2110, 6739)\n",
      "(2110, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INE12363221\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "TV = TfidfVectorizer(sublinear_tf= True, #use a logarithmic form for frequency\n",
    "                       min_df = 5, #minimum numbers of documents a word must be present in to be kept\n",
    "                       norm= 'l2', #ensure all our feature vectors have a euclidian norm of 1\n",
    "                       ngram_range= (1,2))   \n",
    "X = TV.fit_transform(all_complaint).toarray()\n",
    "y = df.as_matrix([\"category_id\"])\n",
    "print(np.shape(X))\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "6739\n"
     ]
    }
   ],
   "source": [
    "print(X[0])\n",
    "print(len(X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INE12363221\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8175355450236966"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try linear SVC \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42\n",
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#do individuaal prediction \n",
    "print(clf.predict(TV.transform(['I have outdated information on my credit report'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DO SAMETHING USING SPACY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Consumer_complaint</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I have outdated information on my credit repor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>I purchased a new car on XXXX XXXX. The car de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>An account on my credit report has a mistaken ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>This company refuses to provide me verificatio...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>This complaint is in regards to Square Two Fin...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Consumer_complaint  category_id\n",
       "1   I have outdated information on my credit repor...            0\n",
       "2   I purchased a new car on XXXX XXXX. The car de...            1\n",
       "7   An account on my credit report has a mistaken ...            0\n",
       "12  This company refuses to provide me verificatio...            2\n",
       "16  This complaint is in regards to Square Two Fin...            2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Consumer_Complaints.csv')\n",
    "#remove all column except input and output \n",
    "col = ['Product', 'Consumer Complaint']\n",
    "df= df[col]\n",
    "#remove null review comments \n",
    "df= df[pd.notnull(df['Consumer Complaint'])]\n",
    "#rename the column from Consumer Complaint to Consumer_complaint\n",
    "df.columns=['Product', 'Consumer_complaint']\n",
    "#factorize the product and rename with categoryid \n",
    "df['category_id'] = df['Product'].factorize()[0]\n",
    "#remove duplicates \n",
    "#remove product id \n",
    "df =df.drop(df.loc[:,['Product']], axis =1 )\n",
    "df=df.drop_duplicates()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "import  spacy\n",
    "#load english language\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Create our list of punctuation marks\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Create our list of stopwords\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outdate information credit report previously dispute remove information seven year old doe meet credit report requirement',\n",
       " 'purchase new car xxxx xxxx car dealer citizen bank day payoff loan good till xxxx xxxx dealer send check day balance checkbook xxxx xxxx notice citizen bank automatic payment check account xxxx xxxx xxxx bank citizen state close loan xxxx xxxx state receive check xxxx xxxx tell believe check long arrive xxxx tell check issue overpay deduct additional interest today xxxx xxxx citizen bank talk supervisor xxxx xxxx xxxx receive letter loan pay date xxxx xxxx refund check include xxxx state hold payment business day loan satisfy check mail xx xx xxxx question delay post dealer payment \\ufeff1 state business day post receive check till xxxx xxxx tell believe ask money state hold payment business day ask simply policy ask receive interest money state believe citizen bank deliberately delay post payment return consumer s money additional interest bank illegal doe hurt consumer ethical money lose minimal thousand car loan month additional interest earn stagger car loan citizen bank afraid trade car year run problem',\n",
       " 'account credit report mistake date mail debt validation letter allow xxxx correct information receive letter mail state experian receive correspondence find suspicious n t write experian s letter word imply incapable write letter deeply offend implication experian figure letter suspicious speak representative incredibly unhelpful effectively answer question ask ignore regard offensive letter dispute process feel representative want satisfy clear receive letter type letter sign letter pay mail letter experian willfully disregard lawful request disgust entire situation like dispute handle appropriately like experian representative contact real explanation letter',\n",
       " 'company refuse provide verification validation debt right fdcpa believe debt',\n",
       " 'complaint regard square financial refer cfpb case numb xxxx regard cach l l c square financial utilize entire social security numb include date birth pfd document list complaint initial complaint cach l l c square financial breach follow identity theft assumption deterrence act xxxx privacy act xxxx xxxx social security xxxx xxxx privacy act carry maximum xxxx fine calendar cap year breach title xxxx xxxx xxxx xxxx xxxx xxxx xxxx solution cach l l c handle correction square financial square financial submit xxxx xxxx xxxx subscriber form list cfpb case xxxx render liable matt addition account numb associate universal datum form use account numb instead ssn dob xxxx xxxx xxxx include removal xxxx xxxx form cfpb case xxxx list pdf document attach case numb square financial contact xxxxxxxxxxxx xxxx xxxx xxxx e mail regard matt addition information sale distribution fax fax scan copy store retrieval system record transmit digitally electronically express write consent information protect copyright publish law xxxx xxxx xxxx xxxx information protect xxxx xxxx xxxx xxxx xxxx freedom speech xxxx xxxx xxxx include uniform commercial code xxxx xxxx right reserve world wide',\n",
       " 'start refinance home mortgage process cash option xx xx necessary document submit xxxx initial review good faith estimate loan close cost base estimate deposit appraisal appraisal come lesser agree reduce loan extent revise estimate little additional close cost point etc numerous revise estimate different loan close cost month reach definite close document want deposit',\n",
       " 'xxxx ex husband apply refinance heloc beneficial loan grant ex husband pass away xxxx xxxx time contact lawyer determine option husband remove title property mortgage lawyer care husband remove title recently attempt apply refinance remove mortgage cash learn attempt refinance unable refinance property deed xxxx find indicate interest property deed file xxxx county illinois recorder xxxx original purchase home ex husband list deed beneficial file mortgage xxxx xxxx property outrage point loan home deed rightful owner deny ability refinance time rightful owner property prior xxxx xxxx xxxx child quit claim father interest sick company way company mislead xxxx customer technically force remain company secure finance reputable company wait month refinance property year pay year consider inheritance quit claim xxxx xxxx xxxx',\n",
       " 'dispute account credit report equifax time \\ufeff1 dispute original creditor xxxx xxxx xxxx xxxx xxxx solution letter receive correspondence proof send copy letter certify mail receipt credit bureau continue verify debt copy proof signature statement dispute credit report equifax continue update account associate creditor',\n",
       " 'mortgage transfer nationstar xxxx xxxx xxxx payment post timely manner send example payment clear bank xxxx xxxx xxxx xxxx payment history receive nationstar payment post xxxx xxxx xxxx xxxx payment clear bank xxxx xxxx xxxx xxxx post account xxxx xxxx xxxx xxxx loan transfer nationstar xxxx receive good letter xxxx welcome package nationstar contact sure payment xxxx tell send post xxxx month payment history allow use website try information time long post money little send send exact document attach state record send history month post money send unable resolve issue nationstar listen review document send proof send month xxxx xxxx payment history deny send month',\n",
       " 'happy xxxx card member year late xx xx xxxx convert card portfolio barclaycard xxxx carry balance start xx xx xxxx barclay overcharge interest expense month instead charge interest carry balance charge entire average balance charge month carry previous month charge interest charge double dip interchange fee purchase equal apr plus interest purchase equivalent interest charge feel practice unethical illegal convert choice xxxx barclaycard mastercard leave lose point acquire previous year completely unfair big financials hate reputation hope folk investigate',\n",
       " 'provocation receive notice credit line decrease nearly available credit reduce xxxx xxxx rough available balance question change provide nob descript response reference xxxx report understand fcra entitle copy report refuse citi far explanation predatory affect utilization credit far subject increase aprs etc high cost credit reason',\n",
       " 'write request assistance look deceptive practice collection law firm appear use tactic violate consumer protection law debt collection practice deprive consumer right dispute xxxx xxxx receive notice company day contact office instruct memo date xxxx xxxx xxxx instruct contact plaintiff attorney court follow instruction provide contact plaintiff attorney phone fax letter xxxx xxxx xxxx dispute debt letter company respond letter date xxxx xxxx xxxx send bill date xxxx request bill balance payment xxxx xxxx dispute owe dispute charge write company fax dispute letter xxxx xxxx xxxx continue dispute owe company send response xxxx xxxx xxxx furnish information dispute owe xxxx xxxx dispute balance inaccurate need proof know charge activity account xxxx xxxx paragraph letter indicate dispute send letter xxxx xxxx xxxx send letter company dispute balance request document company respond xxxx xxxx letter communication xxxx xxxx xxxx receive letter copy default judgment file court clerk s office indicate fail respond judgment fact judgment firm serve original judgment attach dispute letter respond instruct office xxxx different occasion plaintiff fail respond dispute furnish information provide probably unable obtain proof original debt instead use credible legal procedure settle debt utilize unfaithful dirty tactic violate right court commit perjury law file false document court default judgment fail respond fact respond fail furnish proof court house clerk s office tell company notify office contact instead company tell court clerk s office respond summon clerk office grant default judgement base false information respond summon file false affirmation clerk s office',\n",
       " 'dispute inaccurate information chex system credit report initially submit police report xxxx xxxx chex system delete item mention letter item actually list police report word want word word item fraudulent total disregard police report account state fraudulent pay little close attention police report position n t research like report information remove xxxx xxxx xxxx',\n",
       " 'check credit report file complaint cfpb xxxx finally able access dispute form xxxx xxxx account schedule deletion xx xx xxxx record register report numb social security place dispute dispute cart attempt upload instruct form request information matt record order access report \\ufeff1 place screenshots attach design discourage',\n",
       " 'need xxxx facility long afford pay morthage like money pay mark pay',\n",
       " 'attempt open xxxx xxxx account xxxx xxxx unable misinformation credit report advise resolve issue dispute information like victim consumer fraud want issue protection able access information personal gain position open account fradulent act need recieve proper treatment',\n",
       " 'experian allow xxxx pull hard credit inquiry permission xxxx store xxxx xxxx xxxx sc store employee xxxx credit pull try reverse want credit pull remove credit report immediately',\n",
       " 'fha loan bank pay xxxx xxxx pay loan xxxx xxxx instead xxxx xxxx charge interest fee speak bank regard inform unwilling refund charge interest charge exact day loan pay feel charge pay mortgage loan day month word scam',\n",
       " 'toll credit score xxxx end month customer support specialist work case long work fact lower score change dispute thing pay like car payment credit card etc company parkview credit',\n",
       " 'divorce year ago request home loan modification bank america bank america refuse occasion cause process year destroy credit process foreclosure judgment send sheriff sale process correctly pay time year decide sell home list sale day receive offer accept promptly apartment pay deposit sign lease new apartment day close prepare close discover purchase lender unknown bank america sell overdue principal hud require sell home break house appraise foreclosure area contact bank america determine inform buyer process short sale immediately probably able hopefully buyer process continually request update information month process drag lose buyer mortgage payment rend payment apartment continue work home modification process contact lawyer time receive response occassions finally xxxx xxxx receive email xxxx xxxx xxxx xxxx bank america s attorney loan service release xxxx xxxx immediately restart process send packet process submit packet gather info need wife drive house sherrif sale notification xx xx xxxx bank america long work respond sell xxxx process sheriff sale begin sheriff sale process inform lawyer long service loan xxxx confirm bank america complete lastly log sheriff s website discover bank america buy intentionally gain process']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(df):\n",
    "    all_reviews = list()\n",
    "    lines = df[\"Consumer_complaint\"].values.tolist()\n",
    "    for text in lines:\n",
    "        text = text.lower()\n",
    "        text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "        #words=nltk.word_tokenize(text)\n",
    "        # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "        words = parser(text)\n",
    "        words = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in words ]\n",
    "\n",
    "        # Removing stop words\n",
    "        words = [ word for word in words if word not in stop_words and word not in punctuations ]\n",
    "\n",
    "\n",
    "        #words = ''.join(str(words))\n",
    "        #words = ' '.join(str(words))\n",
    "        all_reviews.append(words)\n",
    "        \n",
    "    return all_reviews\n",
    "\n",
    "all_complaint = clean_text(df)\n",
    "all_complaint = [\" \".join(item) for item in all_complaint]\n",
    "all_complaint[0:20]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c', 'd e f']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=[[\"a\",\"b\",\"c\"],[\"d\",\"e\",\"f\"]]\n",
    "l1=[]\n",
    "for x in l :\n",
    "    l1.append(\" \".join(x))\n",
    "l1\n",
    "l2=[\" \".join(item) for item in all_complaint]\n",
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2110, 5572)\n",
      "(2110, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INE12363221\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "TV = TfidfVectorizer(sublinear_tf= True, #use a logarithmic form for frequency\n",
    "                       min_df = 5, #minimum numbers of documents a word must be present in to be kept\n",
    "                       norm= 'l2', #ensure all our feature vectors have a euclidian norm of 1\n",
    "                       ngram_range= (1,2))   \n",
    "X = TV.fit_transform(all_complaint).toarray()\n",
    "y = df.as_matrix([\"category_id\"])\n",
    "print(np.shape(X))\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\INE12363221\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8080568720379147"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try linear SVC \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#do individuaal prediction \n",
    "print(clf.predict(TV.transform(['I have outdated information on my credit report'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
